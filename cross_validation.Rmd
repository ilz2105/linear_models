---
title: "cross_validation"
author: "Lulu Zhang"
date: "11/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(modelr)
library(mgcv)
```

```{r}
nonlin_df = 
  tibble(
    id = 1:100,
    x = runif(100, 0, 1),
    y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
  )

nonlin_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + theme_bw()
```

```{r}
train_df = sample_n(nonlin_df, 80)
test_df = anti_join(nonlin_df, train_df, by = "id")

ggplot(train_df, aes(x = x, y = y)) + 
  geom_point() + 
  geom_point(data = test_df, color = "red")
```

```{r}
linear_mod = lm(y ~ x, data = train_df)
smooth_mod = mgcv::gam(y ~ s(x), data = train_df)
wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)
```

```{r}
train_df %>% 
  add_predictions(smooth_mod) %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = "red")
```

```{r}
train_df %>% 
  add_predictions(wiggly_mod) %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = "red")
```

```{r}
train_df %>% 
  gather_predictions(linear_mod, smooth_mod, wiggly_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_line(aes(y = pred), color = "red") + 
  facet_wrap(~model)
```

no test to see which one is statistically significant bc no pvalue here

use root mean square error model 
```{r}
rmse(linear_mod, test_df)

rmse(smooth_mod, test_df)

rmse(wiggly_mod, test_df)
```

on avg, the squared distance is about 0.8 for the linear model
for the smooth model, its abut 03
wiggly model is about 0.38

no pvalue saying which model is stat sig worse or better

this gives us an idea of how well the testing data 
pick the one that is the best with the testing data
putting mor ein model, will always make rmse go down for training data


```{r}
cv_df = 
  crossv_mc(nonlin_df, 100)
```

```{r}
cv_df %>% pull(train) %>% .[[1]] %>% as_tibble
```

